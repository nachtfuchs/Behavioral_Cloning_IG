{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "#import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "print('Import successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and get an impression of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs created succesfully\n"
     ]
    }
   ],
   "source": [
    "source_path = 'data/driving_log.csv'\n",
    "\n",
    "logs = []\n",
    "reader = csv.reader(open(source_path, 'rt'))\n",
    "for line in reader:\n",
    "    logs.append(line)\n",
    "\n",
    "print('logs created succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs.pop[0]:  ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
      "len(logs[0]):  7\n",
      "logs[0]:  ['IMG/center_2016_12_01_13_30_48_287.jpg', ' IMG/left_2016_12_01_13_30_48_287.jpg', ' IMG/right_2016_12_01_13_30_48_287.jpg', ' 0', ' 0', ' 0', ' 22.14829']\n",
      "logs[1][0]:  IMG/center_2016_12_01_13_30_48_404.jpg\n"
     ]
    }
   ],
   "source": [
    "print('logs.pop[0]: ', logs.pop(0))\n",
    "print('len(logs[0]): ', len(logs[0]))\n",
    "print('logs[0]: ', logs[0])\n",
    "print('logs[1][0]: ', logs[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resize_image(input_image):\n",
    "    '''@brief Reduce image size for computational reasons.\n",
    "    '''\n",
    "    x_size = 48\n",
    "    y_size = 128\n",
    "    return cv2.resize(input_image, (y_size, x_size))\n",
    "\n",
    "def crop_image(input_image):\n",
    "    '''@brief Cut off the sky and lower part of the picture since it contains\n",
    "              little information about the track.\n",
    "    '''\n",
    "    offset_low = 40\n",
    "    offset_high = 140\n",
    "    return input_image[offset_low:offset_high]\n",
    "\n",
    "def change_color_space(input_image):\n",
    "    ''' Return image in S dimension of HSV color space\n",
    "    '''\n",
    "    return  cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "\n",
    "def image_wrapper(input_image):\n",
    "    '''@brief summarize all relevant image processing functions\n",
    "    '''\n",
    "    #return change_color_space(resize_image(crop_image(input_image)))\n",
    "    return resize_image(crop_image(input_image))\n",
    "\n",
    "def img_load(path_to_table, steering_offset):\n",
    "    ''' @brief Load the images from an input path and perform \n",
    "               particular preprocessing operations on them.'''\n",
    "    #read the path to the images\n",
    "    reader = csv.reader(open(source_path, 'rt'))\n",
    "    new_logs = []\n",
    "    for line in reader:\n",
    "        new_logs.append(line) #save the path in a list\n",
    "    #delete first line because it contains unnecessary information\n",
    "    new_logs.pop(0)\n",
    "    #print('logs[0]: ', new_logs[0]) #debug\n",
    "    X = []\n",
    "    y = []\n",
    "    for center, left, right, steering, throttle, brake, speed in new_logs:\n",
    "        #print('center: ', center)\n",
    "#        try: \n",
    "            # preprocess the images and save them in a list\n",
    "            #X.append(image_wrapper(plt.imread('data/'+center))) # include preprocessing\n",
    "            #X.append(cv2.imread('data/'+center)) #exclude preprocessing\n",
    "#        except FileNotFoundError: #debug\n",
    "#            print('center: ', center) #debug\n",
    "#            print('left: ', left) #debug\n",
    "#            print('right: ', right) #debug\n",
    "#            print('len(X_train): ', len(X)) #debug\n",
    "#            print('logs[len(X_train)-1]: ', new_logs[len(X)-1]) #debug\n",
    "        #append left and right images    \n",
    "        #X.append(image_wrapper(plt.imread('data/'+center))) # include preprocessing\n",
    "        #X.append(image_wrapper(plt.imread('data/'+left[1:]))) # include preprocessing\n",
    "        #X.append(image_wrapper(plt.imread('data/'+right[1:]))) # include preprocessing\n",
    "        \n",
    "        X.append(plt.imread('data/'+center)) # exclude preprocessing\n",
    "        X.append(plt.imread('data/'+left[1:])) # exclude preprocessing\n",
    "        X.append(plt.imread('data/'+right[1:])) # exclude preprocessing\n",
    "        \n",
    "        #X.append(cv2.imread('data/'+left[1:]))\n",
    "        #X.append(cv2.imread('data/'+right[1:]))\n",
    "        \n",
    "        #get the steering angle\n",
    "        y.append(float(steering))\n",
    "        #add the steering offset to the left and right images\n",
    "        y.append(float(steering) + steering_offset)\n",
    "        y.append(float(steering) - steering_offset)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into appropriate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_load took:  3.2801823218663535  s minutes to load.\n",
      "len(X_train):  48441\n",
      "len(X_train[0]):  48\n",
      "len(X_train[0][0]):  128\n",
      "len(X_train[0][0][0]):  3\n",
      "len(y_train):  48441\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "X_train, y_train = img_load('data/driving_log.csv', 0.08)\n",
    "print('img_load took: ', (time() - t_start) /60, ' s minutes to load.')\n",
    "print('len(X_train): ', len(X_train)) #debug\n",
    "print('len(X_train[0]): ', len(X_train[0])) #debug\n",
    "print('len(X_train[0][0]): ', len(X_train[0][0])) #debug\n",
    "print('len(X_train[0][0][0]): ', len(X_train[0][0][0])) #debug\n",
    "print('len(y_train): ', len(y_train)) #debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flip images around the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_total):  96882\n",
      "len(y_total):  96882\n"
     ]
    }
   ],
   "source": [
    "#flip the images around the y-axis\n",
    "X_flipped = []\n",
    "y_flipped = []\n",
    "for X in X_train:\n",
    "    X_flipped.append(np.fliplr(X))\n",
    "# adjust the steering by changing the foresign\n",
    "for y in y_train:\n",
    "    y_flipped.append(-y)\n",
    "    \n",
    "# merge flipped data with original data\n",
    "X_total = X_train + X_flipped\n",
    "y_total = y_train + y_flipped\n",
    "\n",
    "print('len(X_total): ', len(X_total))\n",
    "print('len(y_total): ', len(y_total))\n",
    "#print('X_total.shape: ', X_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np.shape:  (96882, 48, 128, 3)\n",
      "y_np.shape:  (96882,)\n"
     ]
    }
   ],
   "source": [
    "X_np = np.array(X_total)\n",
    "y_np = np.array(y_total)\n",
    "print('X_np.shape: ', X_np.shape)\n",
    "print('y_np.shape: ', y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size:  (48, 128, 3)\n",
      "X_np[0]:  [[[132 131  99]\n",
      "  [128 127  97]\n",
      "  [138 134 109]\n",
      "  ..., \n",
      "  [188 225 255]\n",
      "  [188 225 255]\n",
      "  [188 225 255]]\n",
      "\n",
      " [[147 148 116]\n",
      "  [126 125  96]\n",
      "  [116 114  88]\n",
      "  ..., \n",
      "  [193 229 254]\n",
      "  [193 229 254]\n",
      "  [193 229 254]]\n",
      "\n",
      " [[151 154 122]\n",
      "  [126 128  98]\n",
      "  [111 110  83]\n",
      "  ..., \n",
      "  [198 234 255]\n",
      "  [198 234 255]\n",
      "  [198 234 255]]\n",
      "\n",
      " ..., \n",
      " [[110 104  87]\n",
      "  [109 103  86]\n",
      "  [146 140 122]\n",
      "  ..., \n",
      "  [175 171 118]\n",
      "  [158 155 115]\n",
      "  [167 161 134]]\n",
      "\n",
      " [[211 204 170]\n",
      "  [209 202 168]\n",
      "  [209 202 167]\n",
      "  ..., \n",
      "  [179 176 127]\n",
      "  [202 199 153]\n",
      "  [159 155 116]]\n",
      "\n",
      " [[224 211 169]\n",
      "  [224 212 169]\n",
      "  [215 203 160]\n",
      "  ..., \n",
      "  [122 118  86]\n",
      "  [142 140 100]\n",
      "  [192 192 149]]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Shuffle the data\n",
    "X_np, y_np = shuffle(X_np, y_np) \n",
    "image_size = np.shape(np.array(X_np[0]))\n",
    "print('image_size: ', image_size)\n",
    "#print('X_np[0]: ', X_np[0]) #debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that the image preproccessing finished, the neural net needs to be defined in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 48, 128, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 37, 65, 24)    55320       lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 34, 34)    156706      convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 15, 12, 48)    71856       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 14, 10, 64)    18496       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 13, 8, 64)     24640       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 6656)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          7748748     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 8,197,837\n",
      "Trainable params: 8,197,837\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#normalize image depending on the input size of the image\n",
    "if X_np[0].shape[0] == 160:\n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(160,320,3)))\n",
    "    #cut off the sky and hood in the camera images\n",
    "    model.add(Cropping2D(cropping=((70,25),(1,1))))\n",
    "elif X_np[0].shape[0] == 48:\n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(48,128,3)))\n",
    "else:\n",
    "    raise TypeError() #raise a random error\n",
    "\n",
    "#reduce computational load for faster performance\n",
    "#actual neural net layout starts here\n",
    "model.add(Convolution2D(24, 12, 64, activation='relu'))\n",
    "#model.add(MaxPooling2D()) #deal with overfitting\n",
    "model.add(Convolution2D(34, 6, 32, activation='relu'))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(48, 4, 11,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(64, 2, 3,activation='relu'))\n",
    "model.add(Convolution2D(64, 2, 3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))     \n",
    "model.add(Dense(100)) \n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Display overview of the network\n",
    "model.summary()\n",
    "# Network architecture\n",
    "#model = Sequential()\n",
    "#model.add(Flatten(input_shape = (12, 32)))\n",
    "#model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77505 samples, validate on 19377 samples\n",
      "Epoch 1/5\n",
      "   64/77505 [..............................] - ETA: 27056s - loss: 117.1931"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "# train the model\n",
    "# keras model compile, choose optimizer and loss func\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.fit(X_np, y_np, validation_split=0.2, shuffle= True, nb_epoch=5)\n",
    "model.save('model.h5')\n",
    "print('Total training time: ', time() - start_time)\n",
    "print('Model created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
