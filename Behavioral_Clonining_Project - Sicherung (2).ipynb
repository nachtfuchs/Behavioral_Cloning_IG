{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "#import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "print('Import successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and get an impression of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs created succesfully\n"
     ]
    }
   ],
   "source": [
    "source_path = 'data/driving_log.csv'\n",
    "\n",
    "logs = []\n",
    "reader = csv.reader(open(source_path, 'rt'))\n",
    "for line in reader:\n",
    "    logs.append(line)\n",
    "\n",
    "print('logs created succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs.pop[0]:  ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
      "len(logs[0]):  7\n",
      "logs[0]:  ['IMG/center_2016_12_01_13_30_48_287.jpg', ' IMG/left_2016_12_01_13_30_48_287.jpg', ' IMG/right_2016_12_01_13_30_48_287.jpg', ' 0', ' 0', ' 0', ' 22.14829']\n",
      "logs[1][0]:  IMG/center_2016_12_01_13_30_48_404.jpg\n"
     ]
    }
   ],
   "source": [
    "print('logs.pop[0]: ', logs.pop(0))\n",
    "print('len(logs[0]): ', len(logs[0]))\n",
    "print('logs[0]: ', logs[0])\n",
    "print('logs[1][0]: ', logs[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resize_image(input_image):\n",
    "    '''@brief Reduce image size for computational reasons.\n",
    "    '''\n",
    "    x_size = 16\n",
    "    y_size = 32\n",
    "    return cv2.resize(input_image, (y_size, x_size))\n",
    "\n",
    "def crop_image(input_image):\n",
    "    '''@brief Cut off the sky and lower part of the picture since it contains\n",
    "              little information about the track.\n",
    "    '''\n",
    "    offset_low = 40\n",
    "    offset_high = 140\n",
    "    return input_image[offset_low:offset_high]\n",
    "\n",
    "def change_color_space(input_image):\n",
    "    ''' Return image in S dimension of HSV color space\n",
    "    '''\n",
    "    return  cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "\n",
    "def image_wrapper(input_image):\n",
    "    '''@brief summarize all relevant image processing functions\n",
    "    '''\n",
    "    #return change_color_space(resize_image(crop_image(input_image)))\n",
    "    #return resize_image(crop_image(input_image))\n",
    "    return resize_image(input_image)\n",
    "\n",
    "def img_load(path_to_table, steering_offset):\n",
    "    ''' @brief Load the images from an input path and perform \n",
    "               particular preprocessing operations on them.'''\n",
    "    #read the path to the images\n",
    "    reader = csv.reader(open(source_path, 'rt'))\n",
    "    new_logs = []\n",
    "    for line in reader:\n",
    "        new_logs.append(line) #save the path in a list\n",
    "    #delete first line because it contains unnecessary information\n",
    "    new_logs.pop(0)\n",
    "    #print('logs[0]: ', new_logs[0]) #debug\n",
    "    X = []\n",
    "    y = []\n",
    "    for center, left, right, steering, throttle, brake, speed in new_logs:\n",
    "        #append left and right images    \n",
    "        X.append(image_wrapper(plt.imread('data/'+center))) # include preprocessing\n",
    "        X.append(image_wrapper(plt.imread('data/'+left[1:]))) # include preprocessing\n",
    "        X.append(image_wrapper(plt.imread('data/'+right[1:]))) # include preprocessing\n",
    "        \n",
    "        #X.append(plt.imread('data/'+center)) # exclude preprocessing\n",
    "        #X.append(plt.imread('data/'+left[1:])) # exclude preprocessing\n",
    "        #X.append(plt.imread('data/'+right[1:])) # exclude preprocessing\n",
    "        \n",
    "        #X.append(cv2.imread('data/'+left[1:]))\n",
    "        #X.append(cv2.imread('data/'+right[1:]))\n",
    "        \n",
    "        #get the steering angle\n",
    "        y.append(float(steering))\n",
    "        #add the steering offset to the left and right images\n",
    "        y.append(float(steering) + steering_offset)\n",
    "        y.append(float(steering) - steering_offset)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into appropriate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_load took:  8.41559815009435  s minutes to load.\n",
      "len(X_train):  48441\n",
      "len(X_train[0]):  16\n",
      "len(X_train[0][0]):  32\n",
      "len(X_train[0][0][0]):  3\n",
      "len(y_train):  48441\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "X_train, y_train = img_load('data/driving_log.csv', 0.08)\n",
    "print('img_load took: ', (time() - t_start) /60, ' s minutes to load.')\n",
    "print('len(X_train): ', len(X_train)) #debug\n",
    "print('len(X_train[0]): ', len(X_train[0])) #debug\n",
    "print('len(X_train[0][0]): ', len(X_train[0][0])) #debug\n",
    "print('len(X_train[0][0][0]): ', len(X_train[0][0][0])) #debug\n",
    "print('len(y_train): ', len(y_train)) #debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flip images around the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_total):  96882\n",
      "len(y_total):  96882\n"
     ]
    }
   ],
   "source": [
    "#flip the images around the y-axis\n",
    "X_flipped = []\n",
    "y_flipped = []\n",
    "for X in X_train:\n",
    "    X_flipped.append(np.fliplr(X))\n",
    "# adjust the steering by changing the foresign\n",
    "for y in y_train:\n",
    "    y_flipped.append(-y)\n",
    "    \n",
    "# merge flipped data with original data\n",
    "X_total = X_train + X_flipped\n",
    "y_total = y_train + y_flipped\n",
    "\n",
    "print('len(X_total): ', len(X_total))\n",
    "print('len(y_total): ', len(y_total))\n",
    "#print('X_total.shape: ', X_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np.shape:  (96882, 16, 32, 3)\n",
      "y_np.shape:  (96882,)\n"
     ]
    }
   ],
   "source": [
    "X_np = np.array(X_total)\n",
    "y_np = np.array(y_total)\n",
    "print('X_np.shape: ', X_np.shape)\n",
    "print('y_np.shape: ', y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size:  (16, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Shuffle the data\n",
    "X_np, y_np = shuffle(X_np, y_np) \n",
    "image_size = np.shape(np.array(X_np[0]))\n",
    "print('image_size: ', image_size)\n",
    "#print('X_np[0]: ', X_np[0]) #debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that the image preproccessing finished, the neural net needs to be defined in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 16, 32, 3)     0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 13, 17, 24)    4632        lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 12, 10, 34)    13090       convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 4080)          0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 256)           1044736     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 50)            12850       dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 10)            510         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             11          dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,075,829\n",
      "Trainable params: 1,075,829\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#normalize image depending on the input size of the image\n",
    "if X_np[0].shape[0] == 160:\n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(160,320,3)))\n",
    "    #cut off the sky and hood in the camera images\n",
    "    model.add(Cropping2D(cropping=((70,25),(1,1))))\n",
    "elif X_np[0].shape[0] == 48:\n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(48,128,3)))\n",
    "elif X_np[0].shape[0] == 16:\n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(16,32,3)))\n",
    "else:\n",
    "    raise TypeError() #raise a random error\n",
    "\n",
    "#reduce computational load for faster performance\n",
    "#actual neural net layout starts here\n",
    "model.add(Convolution2D(24, 4, 16, activation='relu'))\n",
    "#model.add(MaxPooling2D()) #deal with overfitting\n",
    "model.add(Convolution2D(34, 2, 8, activation='relu'))\n",
    "#model.add(MaxPooling2D())\n",
    "# model.add(Convolution2D(48, 4, 11, subsample=(2,2),activation='relu'))\n",
    "# model.add(Convolution2D(64, 2, 3, activation='relu'))\n",
    "# model.add(Convolution2D(64, 2, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))     \n",
    "#model.add(Dense(100)) \n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Display overview of the network\n",
    "model.summary()\n",
    "# Network architecture\n",
    "#model = Sequential()\n",
    "#model.add(Flatten(input_shape = (12, 32)))\n",
    "#model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77505 samples, validate on 19377 samples\n",
      "Epoch 1/5\n",
      "77505/77505 [==============================] - 532s - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 2/5\n",
      "77505/77505 [==============================] - 506s - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 3/5\n",
      "77505/77505 [==============================] - 467s - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 4/5\n",
      "77505/77505 [==============================] - 443s - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "77505/77505 [==============================] - 573s - loss: 0.0051 - val_loss: 0.0051\n",
      "Total training time:  2525.6071779727936\n",
      "Model created successfully.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "# train the model\n",
    "# keras model compile, choose optimizer and loss func\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.fit(X_np, y_np, validation_split=0.2, shuffle= True, nb_epoch=5)\n",
    "model.save('model.h5')\n",
    "print('Total training time: ', time() - start_time)\n",
    "print('Model created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
